##### Availability of Data (Ref from Sheets)
- Summary
	- 22 datasets available (~5,63,533k rows)
- NL - Codegen
	- 16 datasets available (~45,035k rows)
-  Classification tasks
	- 46 datasets available (~7,144k rows)
- Text generation / based on the prompt
	- 5 datasets available (~60,119k rows)
- NL - SQL
	- 4 datasets available (~293k rows) (*Limited*)
		- 2 unknown licenses
- NL - Structural
	- 5 datasets available (~1.7k rows) (*Very Limited*)
		- 3 unknown licenses
	- "JSON Extraction" in Sheets
- Code - Unit test gen.
	- *Very Very Limited*
	- Only 1 source in Sheets - Not very reliable
	- https://github.com/openai/human-eval/tree/master
- In Context QA
	- With context - *Very Limited*

---
##### Categories
- Text Summarization  
- Input = Natural Language and Output = Structural. Input will have a defined schema for example, JSON schema and based on the query output will have the schema filled with answer   
- Input = Natural Language and Output = SQL. Input will have a defined SQL DB schema for example, CREATE TABLE... and based on the query output will have the SQL query 
- Input = Natural Language and Output = Code Generation  
- Input = Code and "Write a unit test" prompt and Output = Unit test generation  
- Question Answering provided some context  
- Classification tasks, for example, Input = some email with classes like ("satisfactory", "good", "bad", etc) and Output =  "good"
- Text generation / based on the prompt