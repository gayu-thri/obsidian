MMLU
https://docs.confident-ai.com/docs/benchmarks-mmlu
https://huggingface.co/meta-llama

MMLU Analysis:
- How the score MMLU is impacted by different datacut??
- What is the reason for MMLU score variations among different LLAMA versions??

---

Training overview:
- Llama 3 paper for overview
- https://huggingface.co/NousResearch/Llama-2-7b-chat-hf
DPO  
Architectures used for LLMs  
- [https://www.labellerr.com/blog/exploring-architectures-and-configurations-for-large-language-models-llms/amp/](https://www.labellerr.com/blog/exploring-architectures-and-configurations-for-large-language-models-llms/amp/)  
- [https://whylabs.ai/learning-center/introduction-to-llms/understanding-large-language-model-architectures](https://whylabs.ai/learning-center/introduction-to-llms/understanding-large-language-model-architectures)  
Floating point operations (FLoPs)  
Mixed precision (fp16, fp32)  
Optimiser (Adam, Adafactor)  
RoPE  
SwiGLU activation function  
Gradient checkpoints  
  
Code  
- Fine-tuning BERT or GPT-like models (HuggingFace NLP Course)  
- [https://huggingface.co/learn/nlp-course/en/chapter7/6](https://huggingface.co/learn/nlp-course/en/chapter7/6)  
- [https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/illustrated-transformer/)(Edited)

