**GPU usage in LilacML**
Tried to check if GPU can be used for computing embedding in LilacML. It's already handled in their code with a function `setup_model_device()` which has these lines  
```  
elif torch.cuda.is_available():  
    preferred_device = 'cuda'  
```  
With their torch version, there was an error saying "Install a pytorch version compiled with version of your CUDA driver..."  
  
On installing the correct version, it worked with GPU.  

Experimented with "knkarthick/dialogsum" dataset  
  
> With GPU: `11 mins 25 seconds`  
> Without GPU: `1 minute 18 seconds`  
  
There was significant improvement (i.e., around 90% in this case) by making use of single GPU​

---

Configuration/usage of multiple GPUs does not appear to be there in Lilac's codebase. ​  
- However, because they are making using of `SentenceTransformers`, 
	- We can try to change the code to make it support.
	- Some references below,
		- https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/computing-embeddings/computing_embeddings_multi_gpu.py  
		- https://www.kaggle.com/code/aisuko/computing-embeddings-with-multi-gpus