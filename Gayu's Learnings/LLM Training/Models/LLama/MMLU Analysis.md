- Massive Multitask Language Understanding (MMLU)
- Tests *==zero-shot understanding==* (General knowledge of a model)
- Zero-shot MMLU
	- Tasks it has never seen before - No specific examples / training data
- MMLU 5-shot evaluation
	- Llama 3 uses it
	- 5 example problems + Ask to solve additional one
	- Tests this -> How well model can generalise from small amount of task-specific info
- MMLU
	- Has questions across 57 subjects - astronomy, biology, micro-ecnomics, etc..
	- Broad spectrum of human knowledge

>*The LLM is scored based on the percentage of questions it gets correct.*

